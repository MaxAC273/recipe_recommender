{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a725c034",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Rows</th>\n",
       "      <th>Number of Columns</th>\n",
       "      <th>Columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ingr_map</th>\n",
       "      <td>11659</td>\n",
       "      <td>7</td>\n",
       "      <td>raw_ingr, raw_words, processed, len_proc, repl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_recipes</th>\n",
       "      <td>231637</td>\n",
       "      <td>12</td>\n",
       "      <td>name, id, minutes, contributor_id, submitted, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_interactions</th>\n",
       "      <td>1132367</td>\n",
       "      <td>5</td>\n",
       "      <td>user_id, recipe_id, date, rating, review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_users</th>\n",
       "      <td>25076</td>\n",
       "      <td>6</td>\n",
       "      <td>u, techniques, items, n_items, ratings, n_ratings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_recipes</th>\n",
       "      <td>178265</td>\n",
       "      <td>8</td>\n",
       "      <td>id, i, name_tokens, ingredient_tokens, steps_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interactions_validation</th>\n",
       "      <td>7023</td>\n",
       "      <td>6</td>\n",
       "      <td>user_id, recipe_id, date, rating, u, i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interactions_train</th>\n",
       "      <td>698901</td>\n",
       "      <td>6</td>\n",
       "      <td>user_id, recipe_id, date, rating, u, i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interactions_test</th>\n",
       "      <td>12455</td>\n",
       "      <td>6</td>\n",
       "      <td>user_id, recipe_id, date, rating, u, i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Number of Rows Number of Columns  \\\n",
       "ingr_map                         11659                 7   \n",
       "raw_recipes                     231637                12   \n",
       "raw_interactions               1132367                 5   \n",
       "pp_users                         25076                 6   \n",
       "pp_recipes                      178265                 8   \n",
       "interactions_validation           7023                 6   \n",
       "interactions_train              698901                 6   \n",
       "interactions_test                12455                 6   \n",
       "\n",
       "                                                                   Columns  \n",
       "ingr_map                 raw_ingr, raw_words, processed, len_proc, repl...  \n",
       "raw_recipes              name, id, minutes, contributor_id, submitted, ...  \n",
       "raw_interactions                  user_id, recipe_id, date, rating, review  \n",
       "pp_users                 u, techniques, items, n_items, ratings, n_ratings  \n",
       "pp_recipes               id, i, name_tokens, ingredient_tokens, steps_t...  \n",
       "interactions_validation             user_id, recipe_id, date, rating, u, i  \n",
       "interactions_train                  user_id, recipe_id, date, rating, u, i  \n",
       "interactions_test                   user_id, recipe_id, date, rating, u, i  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load the datasets\n",
    "ingr_map = pd.read_pickle(\"ingr_map.pkl\")\n",
    "raw_recipes = pd.read_csv(\"RAW_recipes.csv\")\n",
    "raw_interactions = pd.read_csv(\"RAW_interactions.csv\")\n",
    "pp_users = pd.read_csv(\"PP_users.csv\")\n",
    "pp_recipes = pd.read_csv(\"PP_recipes.csv\")\n",
    "interactions_validation = pd.read_csv(\"interactions_validation.csv\")\n",
    "interactions_train = pd.read_csv(\"interactions_train.csv\")\n",
    "interactions_test = pd.read_csv(\"interactions_test.csv\")\n",
    "\n",
    "\n",
    "# Show some basic information about each dataset\n",
    "datasets = {\n",
    "    'ingr_map': ingr_map,\n",
    "    'raw_recipes': raw_recipes,\n",
    "    'raw_interactions': raw_interactions,\n",
    "    'pp_users': pp_users,\n",
    "    'pp_recipes': pp_recipes,\n",
    "    'interactions_validation': interactions_validation,\n",
    "    'interactions_train': interactions_train,\n",
    "    'interactions_test': interactions_test\n",
    "}\n",
    "\n",
    "info_dict = {}\n",
    "\n",
    "for name, dataset in datasets.items():\n",
    "    info_dict[name] = {\n",
    "        'Number of Rows': dataset.shape[0],\n",
    "        'Number of Columns': dataset.shape[1],\n",
    "        'Columns': ', '.join(dataset.columns)\n",
    "    }\n",
    "\n",
    "info_df = pd.DataFrame(info_dict).T\n",
    "info_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ae698e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_recipes_df = pd.read_csv('RAW_recipes.csv')\n",
    "raw_interactions_df = pd.read_csv(\"RAW_interactions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb023bdb",
   "metadata": {},
   "source": [
    "# SVD collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6914aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d5bce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_interactions_df[['user_id', 'recipe_id', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5b6bae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.2236  1.2252  1.2139  1.2206  1.2193  1.2205  0.0039  \n",
      "MAE (testset)     0.7417  0.7416  0.7362  0.7394  0.7397  0.7397  0.0020  \n",
      "Fit time          12.16   12.13   12.30   12.57   11.94   12.22   0.21    \n",
      "Test time         1.44    1.37    1.32    1.41    1.67    1.44    0.12    \n",
      "{'test_rmse': array([1.22363968, 1.22522626, 1.21388836, 1.22058748, 1.21926462]), 'test_mae': array([0.74166363, 0.7416333 , 0.73620976, 0.73935663, 0.73973383]), 'fit_time': (12.156907081604004, 12.127675294876099, 12.29780387878418, 12.570320844650269, 11.936063051223755), 'test_time': (1.437319040298462, 1.3681721687316895, 1.316875696182251, 1.4091508388519287, 1.6688730716705322)}\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(data, reader)\n",
    "model = SVD()\n",
    "\n",
    "cross_validation_results = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "print(cross_validation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0e450db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.2214\n",
      "MAE:  0.7404\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test set (e.g., 75% training, 25% testing)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Train the model on the training set\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Compute and print the accuracy metrics\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb248f9",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for SVD collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "136f6400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import Dataset, Reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c47eca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score:  1.2161208333623452\n",
      "Best parameters:  {'n_factors': 50, 'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_factors': [50, 100, 150],\n",
    "    'n_epochs': [20, 30, 40],\n",
    "    'lr_all': [0.002, 0.005],\n",
    "    'reg_all': [0.02, 0.1]\n",
    "}\n",
    "\n",
    "# Setup grid search\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "\n",
    "# Load the dataset\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(raw_interactions_df[['user_id', 'recipe_id', 'rating']], reader)\n",
    "\n",
    "# Run grid search\n",
    "gs.fit(data)\n",
    "\n",
    "print(\"Best RMSE score: \", gs.best_score['rmse'])\n",
    "print(\"Best parameters: \", gs.best_params['rmse'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b46f0f",
   "metadata": {},
   "source": [
    "# Using the Best Parameters to Train the SVD collaborative filtering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3422380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.2155\n",
      "MAE:  0.7407\n"
     ]
    }
   ],
   "source": [
    "# Setup the SVD model with the best parameters\n",
    "optimized_SVD = SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.1)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(raw_interactions_df[['user_id', 'recipe_id', 'rating']], reader)\n",
    "\n",
    "# Split your dataset into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Train the model on the trainset\n",
    "optimized_SVD.fit(trainset)\n",
    "\n",
    "# Make predictions on the testset\n",
    "predictions = optimized_SVD.test(testset)\n",
    "\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97969f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.2099  1.2150  1.2124  1.2163  1.2117  1.2130  0.0023  \n",
      "MAE (testset)     0.7381  0.7407  0.7399  0.7421  0.7398  0.7401  0.0013  \n",
      "Fit time          9.98    9.80    9.83    10.45   10.56   10.12   0.32    \n",
      "Test time         2.78    2.39    2.51    2.52    2.54    2.55    0.13    \n",
      "{'test_rmse': array([1.20986348, 1.21495517, 1.21239871, 1.21627694, 1.21166121]), 'test_mae': array([0.73814761, 0.74072785, 0.73988309, 0.74213283, 0.73976056]), 'fit_time': (9.978832960128784, 9.798351049423218, 9.83065915107727, 10.449662208557129, 10.555390119552612), 'test_time': (2.7790751457214355, 2.3928768634796143, 2.5148427486419678, 2.5208659172058105, 2.5412588119506836)}\n"
     ]
    }
   ],
   "source": [
    "cross_validation_optimized_SVD = cross_validate(optimized_SVD, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "print(cross_validation_optimized_SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48277860",
   "metadata": {},
   "source": [
    "# Co-clustering Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d01bdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.co_clustering.CoClustering at 0x7fac2163fa00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import CoClustering\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(raw_interactions_df[['user_id', 'recipe_id', 'rating']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "co_clustering_model = CoClustering()\n",
    "co_clustering_model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c482b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3097\n",
      "MAE:  0.7562\n"
     ]
    }
   ],
   "source": [
    "predictions = co_clustering_model.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3604c938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score:  1.3103096749322833\n",
      "Best parameters:  {'n_cltr_u': 3, 'n_cltr_i': 5, 'n_epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_cltr_u': [3, 5, 7], 'n_cltr_i': [3, 5, 7], 'n_epochs': [20, 30, 40]}\n",
    "gs = GridSearchCV(CoClustering, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "\n",
    "print(\"Best RMSE score: \", gs.best_score['rmse'])\n",
    "print(\"Best parameters: \", gs.best_params['rmse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bef5bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.co_clustering.CoClustering at 0x7fac2165e130>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Co-clustering model with the best parameters\n",
    "model = CoClustering(n_cltr_u=3, n_cltr_i=5, n_epochs=20)\n",
    "\n",
    "# Train the model on the entire dataset\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "model.fit(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86ed1c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3041\n",
      "MAE:  0.7479\n"
     ]
    }
   ],
   "source": [
    "predictions = model.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb51b87",
   "metadata": {},
   "source": [
    "# Content-based Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57ef6122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(552,\n",
       " dietary                  165091\n",
       " easy                     126062\n",
       " low-in-something          85776\n",
       " 60-minutes-or-less        69990\n",
       " meat                      56042\n",
       " 30-minutes-or-less        55077\n",
       " vegetables                53814\n",
       " taste-mood                52143\n",
       " 4-hours-or-less           49497\n",
       " north-american            48479\n",
       " 3-steps-or-less           44933\n",
       " 15-minutes-or-less        43934\n",
       " low-sodium                43349\n",
       " desserts                  43203\n",
       " low-carb                  42189\n",
       " healthy                   40340\n",
       " dinner-party              37561\n",
       " low-cholesterol           36743\n",
       " low-calorie               36429\n",
       " vegetarian                35651\n",
       " beginner-cook             35561\n",
       " 5-ingredients-or-less     35466\n",
       " holiday-event             34920\n",
       " inexpensive               32619\n",
       " low-protein               32522\n",
       " low-saturated-fat         31378\n",
       " fruit                     31324\n",
       " oven                      31180\n",
       " american                  31179\n",
       " eggs-dairy                30142\n",
       " pasta-rice-and-grains     27084\n",
       " kid-friendly              27074\n",
       " side-dishes               26902\n",
       " healthy-2                 26619\n",
       " comfort-food              26136\n",
       " european                  24912\n",
       " presentation              24470\n",
       " poultry                   24160\n",
       " lunch                     23800\n",
       " for-1-or-2                23084\n",
       " low-fat                   22170\n",
       " stove-top                 22095\n",
       " seasonal                  21933\n",
       " weeknight                 20948\n",
       " chicken                   20381\n",
       " appetizers                20379\n",
       " brunch                    18927\n",
       " to-go                     18524\n",
       " for-large-groups          17391\n",
       " beef                      17074\n",
       " one-dish-meal             16807\n",
       " cheese                    15147\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Tags for Content-based features\n",
    "import ast\n",
    "\n",
    "recipe_data = pd.read_csv(\"RAW_recipes.csv\")\n",
    "\n",
    "# Parsing the tags from string representation of list to actual list\n",
    "recipe_data['tags'] = recipe_data['tags'].apply(ast.literal_eval)\n",
    "\n",
    "# Exploring the unique tags and their frequencies\n",
    "all_tags = [tag for sublist in recipe_data['tags'] for tag in sublist]\n",
    "unique_tags = set(all_tags)\n",
    "tag_frequency = pd.Series(all_tags).value_counts()\n",
    "\n",
    "num_unique_tags = len(unique_tags)\n",
    "selected_indices = [4,5,8, 11] + list(range(13, 61))\n",
    "selected_tags = tag_frequency.iloc[selected_indices]\n",
    "\n",
    "\n",
    "num_unique_tags, selected_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b275c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding tags to speed up computation\n",
    "top_tags = selected_tags.index.tolist()\n",
    "\n",
    "# Initializing columns for top tags with default value 0\n",
    "for tag in top_tags:\n",
    "    recipe_data[f'tag_{tag}'] = 0\n",
    "\n",
    "# Setting the value to 1 if the recipe contains the tag\n",
    "for index, row in recipe_data.iterrows():\n",
    "    for tag in top_tags:\n",
    "        if tag in row['tags']:\n",
    "            recipe_data.at[index, f'tag_{tag}'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62cd4f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bg/hdj9jw_j33g1vg7x_rmvr9lc0000gn/T/ipykernel_10539/1372912005.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recipe_tags_data.rename(columns={'id': 'recipe_id'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Merging the user ratings data (interactions_data) with the one-hot encoded tags from recipe_data\n",
    "# The merging key will be 'recipe_id'\n",
    "\n",
    "interactions_data = pd.read_csv(\"RAW_interactions.csv\")\n",
    "\n",
    "# Selecting relevant columns from recipe_data (recipe_id and one-hot encoded tags)\n",
    "recipe_tags_data = recipe_data[['id'] + [col for col in recipe_data.columns if col.startswith('tag_')]]\n",
    "\n",
    "# Renaming 'id' column to 'recipe_id' for consistency\n",
    "recipe_tags_data.rename(columns={'id': 'recipe_id'}, inplace=True)\n",
    "\n",
    "# Merging the datasets\n",
    "merged_data = interactions_data.merge(recipe_tags_data, how='left', on='recipe_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12c3510a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>tag_dietary</th>\n",
       "      <th>tag_easy</th>\n",
       "      <th>tag_low-in-something</th>\n",
       "      <th>tag_60-minutes-or-less</th>\n",
       "      <th>tag_meat</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_seasonal</th>\n",
       "      <th>tag_weeknight</th>\n",
       "      <th>tag_chicken</th>\n",
       "      <th>tag_appetizers</th>\n",
       "      <th>tag_brunch</th>\n",
       "      <th>tag_to-go</th>\n",
       "      <th>tag_for-large-groups</th>\n",
       "      <th>tag_beef</th>\n",
       "      <th>tag_one-dish-meal</th>\n",
       "      <th>tag_cheese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38094</td>\n",
       "      <td>40893</td>\n",
       "      <td>2003-02-17</td>\n",
       "      <td>4</td>\n",
       "      <td>Great with a salad. Cooked on top of stove for...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1293707</td>\n",
       "      <td>40893</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>5</td>\n",
       "      <td>So simple, so delicious! Great for chilly fall...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8937</td>\n",
       "      <td>44394</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>This worked very well and is EASY.  I used not...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126440</td>\n",
       "      <td>85009</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>5</td>\n",
       "      <td>I made the Mexican topping and took it to bunk...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57222</td>\n",
       "      <td>85009</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>Made the cheddar bacon topping, adding a sprin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id        date  rating  \\\n",
       "0    38094      40893  2003-02-17       4   \n",
       "1  1293707      40893  2011-12-21       5   \n",
       "2     8937      44394  2002-12-01       4   \n",
       "3   126440      85009  2010-02-27       5   \n",
       "4    57222      85009  2011-10-01       5   \n",
       "\n",
       "                                              review  tag_dietary  tag_easy  \\\n",
       "0  Great with a salad. Cooked on top of stove for...            1         1   \n",
       "1  So simple, so delicious! Great for chilly fall...            1         1   \n",
       "2  This worked very well and is EASY.  I used not...            1         1   \n",
       "3  I made the Mexican topping and took it to bunk...            0         1   \n",
       "4  Made the cheddar bacon topping, adding a sprin...            0         1   \n",
       "\n",
       "   tag_low-in-something  tag_60-minutes-or-less  tag_meat  ...  tag_seasonal  \\\n",
       "0                     0                       0         0  ...             0   \n",
       "1                     0                       0         0  ...             0   \n",
       "2                     0                       0         0  ...             1   \n",
       "3                     0                       0         0  ...             0   \n",
       "4                     0                       0         0  ...             0   \n",
       "\n",
       "   tag_weeknight  tag_chicken  tag_appetizers  tag_brunch  tag_to-go  \\\n",
       "0              1            0               0           0          0   \n",
       "1              1            0               0           0          0   \n",
       "2              0            0               0           0          1   \n",
       "3              0            0               0           0          0   \n",
       "4              0            0               0           0          0   \n",
       "\n",
       "   tag_for-large-groups  tag_beef  tag_one-dish-meal  tag_cheese  \n",
       "0                     0         0                  0           0  \n",
       "1                     0         0                  0           0  \n",
       "2                     1         0                  0           0  \n",
       "3                     0         0                  0           0  \n",
       "4                     0         0                  0           0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling missing values in tag columns with zeros\n",
    "merged_data.fillna({col: 0 for col in merged_data.columns if col.startswith('tag_')}, inplace=True)\n",
    "\n",
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30e42f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data2= merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f667095",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Content-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40e3fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Prepare the dataset for content-based model\n",
    "X = merged_data.drop(columns=['user_id', 'recipe_id', 'rating', 'review', 'date'])\n",
    "y = merged_data['rating']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train RandomForest model\n",
    "content_model = RandomForestRegressor()\n",
    "content_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_content = content_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b4305b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1.6841104017151067\n",
      "Root Mean Squared Error (RMSE): 1.2977327928796076\n",
      "Mean Absolute Error (MAE): 0.8311654118787669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions_content)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "rmse = mean_squared_error(y_test, predictions_content, squared=False)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions_content)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b5084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizing hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a54eba",
   "metadata": {},
   "source": [
    "Best parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1cb0317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.6006633320865211\n",
      "RMSE: 1.2651732419263857\n",
      "MAE: 0.8456339830113258\n"
     ]
    }
   ],
   "source": [
    "# Create a new model with the best parameters\n",
    "optimized_rf = RandomForestRegressor(max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300)\n",
    "\n",
    "# Retrain the model on the entire training set\n",
    "optimized_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = optimized_rf.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1b54468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 1.5944072085619527\n",
      "Mean RMSE: 1.2627100066704786\n",
      "Mean MAE: 0.8473926819010259\n"
     ]
    }
   ],
   "source": [
    "# Running cross-validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "optimized_rf = RandomForestRegressor(max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300)\n",
    "num_folds = 5\n",
    "\n",
    "mse_scores = cross_val_score(optimized_rf, X, y, scoring='neg_mean_squared_error', cv=num_folds)\n",
    "mse_scores = -mse_scores\n",
    "print(\"Mean MSE:\", mse_scores.mean())\n",
    "\n",
    "rmse_scores = cross_val_score(optimized_rf, X, y, scoring='neg_root_mean_squared_error', cv=num_folds)\n",
    "rmse_scores = -rmse_scores \n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "\n",
    "mae_scores = cross_val_score(optimized_rf, X, y, scoring='neg_mean_absolute_error', cv=num_folds)\n",
    "mae_scores = -mae_scores \n",
    "print(\"Mean MAE:\", mae_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af10056",
   "metadata": {},
   "source": [
    "# Creating a Hybrid Model with collaborative filtering and content-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cc3fd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fab35d8f280>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the models individually\n",
    "# RandomForest\n",
    "optimized_rf = RandomForestRegressor(max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300)\n",
    "\n",
    "X = merged_data.drop(columns=['user_id', 'recipe_id', 'rating', 'review', 'date'])\n",
    "y = merged_data['rating']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "optimized_rf.fit(X_train, y_train)\n",
    "\n",
    "# SVD\n",
    "optimized_SVD = SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.1)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(raw_interactions_df[['user_id', 'recipe_id', 'rating']], reader)\n",
    "trainset = data.build_full_trainset()\n",
    "optimized_SVD.fit(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea978595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Optimizing model weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_columns = [col for col in merged_data2.columns if col.startswith('tag_')]\n",
    "X = merged_data2[feature_columns]\n",
    "y = merged_data2['rating']\n",
    "\n",
    "user_ids = merged_data2['user_id']\n",
    "item_ids = merged_data2['recipe_id']\n",
    "\n",
    "X_train, X_test, y_train, y_test, user_ids_train, user_ids_test, item_ids_train, item_ids_test = train_test_split(\n",
    "    X, y, user_ids, item_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Create the training dataset for SVD\n",
    "train_data = pd.DataFrame({\n",
    "    'user_id': user_ids_train,\n",
    "    'item_id': item_ids_train,\n",
    "    'rating': y_train\n",
    "})\n",
    "train_data = Dataset.load_from_df(train_data, reader)\n",
    "trainset = train_data.build_full_trainset()\n",
    "\n",
    "def weighted_prediction(user_id, item_id, features, weight_rf, weight_svd):\n",
    "    rf_prediction = optimized_rf.predict([features])[0]\n",
    "    svd_prediction = optimized_SVD.predict(user_id, item_id).est\n",
    "    return weight_rf * rf_prediction + weight_svd * svd_prediction\n",
    "\n",
    "def compute_error(weights, user_ids, item_ids, features, actual_ratings):\n",
    "    weight_rf, weight_svd = weights\n",
    "    predictions = [\n",
    "        weighted_prediction(user_id, item_id, feature, weight_rf, weight_svd)\n",
    "        for user_id, item_id, feature in zip(user_ids, item_ids, features)\n",
    "    ]\n",
    "    return mean_squared_error(actual_ratings, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db0aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41773b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "subset_size = 10000\n",
    "subset_indices = np.random.choice(X_train.index, subset_size, replace=False)\n",
    "\n",
    "X_subset = X_train.loc[subset_indices].values\n",
    "y_subset = y_train.loc[subset_indices].values\n",
    "user_ids_subset = user_ids_train.loc[subset_indices].values\n",
    "item_ids_subset = item_ids_train.loc[subset_indices].values\n",
    "\n",
    "# Initial guesses for weights\n",
    "initial_weights = [0.5, 0.5]\n",
    "\n",
    "# The bounds ensure that weights are between 0 and 1\n",
    "bounds = [(0, 1), (0, 1)]\n",
    "\n",
    "# Perform the optimization with a tolerance value\n",
    "result = minimize(\n",
    "    compute_error,\n",
    "    initial_weights,\n",
    "    args=(user_ids_subset, item_ids_subset, X_subset, y_subset),\n",
    "    bounds=bounds,\n",
    "    method='SLSQP',  # Sequential Least Squares Programming\n",
    "    tol=1e-3  # Adjust the tolerance for faster convergence\n",
    ")\n",
    "\n",
    "optimized_weights = result.x\n",
    "print(\"Optimized weights:\", optimized_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa02e2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized weights: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimized weights:\", optimized_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model with optimized weights\n",
    "\n",
    "X_test_rf = merged_data2.drop(columns=['user_id', 'recipe_id', 'date', 'rating', 'review']) # Prepare the data for the RandomForest model\n",
    "\n",
    "\n",
    "test_data_svd = merged_data2[['user_id', 'recipe_id']] # Prepare the data for the SVD model\n",
    "\n",
    "\n",
    "y_true = merged_data2['rating'] # Actual ratings for evaluation\n",
    "\n",
    "weight_rf = 0\n",
    "weight_svd = 1\n",
    "\n",
    "\n",
    "hybrid_predictions = []\n",
    "for index, row in merged_data2.iterrows():\n",
    "    # Get features for RandomForest\n",
    "    features_rf = row.drop(['user_id', 'recipe_id', 'date', 'rating', 'review']).values.reshape(1, -1)\n",
    "    \n",
    "    # Make predictions using both models\n",
    "    rf_pred = optimized_rf.predict(features_rf)[0]\n",
    "    svd_pred = optimized_SVD.predict(str(row['user_id']), str(row['recipe_id'])).est\n",
    "    \n",
    "    # Combine predictions using a weighted average\n",
    "    hybrid_pred = (rf_pred * weight_rf) + (svd_pred * weight_svd)\n",
    "    hybrid_predictions.append(hybrid_pred)\n",
    "\n",
    "# Evaluate the hybrid model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(y_true, hybrid_predictions)\n",
    "rmse = mean_squared_error(y_true, hybrid_predictions, squared=False)\n",
    "mae = mean_absolute_error(y_true, hybrid_predictions)\n",
    "\n",
    "print(f'MSE: {mse}, RMSE: {rmse}, MAE: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcf3adbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.5995958057022754, RMSE: 1.2647512821508724, MAE: 0.8492393396162298\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE: {mse}, RMSE: {rmse}, MAE: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78911c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
